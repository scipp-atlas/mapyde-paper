\pdfoutput=1
\documentclass{article}

\usepackage{arxiv}

\usepackage{authblk}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{cleveref}
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{doi}
\usepackage{xcolor}
\usepackage[english=american,autostyle=true,autopunct,csdisplay]{csquotes}

\usepackage[finalizecache=true,newfloat=true]{minted} % change to "frozencache=true for submission to arxiv
\usepackage{float}          % to use \begin{listing}[H]
\usemintedstyle{friendly}
\setminted[toml]{numbersep=5pt, frame=lines, framesep=2mm, gobble=0}
\setminted[ini]{numbersep=5pt, frame=lines, framesep=2mm, gobble=0}
%\setminted[json]{numbersep=5pt, frame=lines, framesep=2mm, gobble=0}
\setminted[python]{numbersep=5pt, frame=lines, framesep=2mm, gobble=0, linenos}
\setminted{frame=single,framesep=10pt}
%\BeforeBeginEnvironment{minted}{\vspace{-0.2cm}}
%\AfterEndEnvironment{minted}{\vspace{-0.2cm}}
\usepackage{caption}
\captionsetup[listing]{skip=-4pt}

\usepackage{subcaption}

\usepackage{tikz}
\usetikzlibrary{calc,positioning,shapes.geometric,backgrounds,fit,shadows.blur,arrows.meta}

\usepackage[backend=biber,sorting=none,citestyle=numeric-comp]{biblatex}
\renewbibmacro{in:}{}
\addbibresource{references.bib}

\newcommand{\chioz}{\ensuremath{\widetilde{\chi}_{1}^{0}}}
\newcommand{\chiopm}{\ensuremath{\widetilde{\chi}_{1}^{\pm}}}
\newcommand{\chitpm}{\ensuremath{\widetilde{\chi}_{2}^{\pm}}}
\newcommand{\chitz}{\ensuremath{\widetilde{\chi}_{2}^{0}}}
\newcommand{\chithz}{\ensuremath{\widetilde{\chi}_{3}^{0}}}
\newcommand{\slepton}{\ensuremath{\widetilde{\ell}}}
\newcommand{\met}{\ensuremath{E_{\mathrm{T}}^{\mathrm{miss}}}}
\newcommand{\mapyde}{\texttt{mapyde}}
\newcommand{\simpleanalysis}{\texttt{SimpleAnalysis}}
\newcommand{\madgraph}{\textsc{MadGraph}}
\newcommand{\madgraphfull}{\textsc{MadGraph5\_aMC@NLO}}
\newcommand{\madspin}{\textsc{MadSpin}}
\newcommand{\pythia}{\textsc{Pythia8}}
\newcommand{\delphes}{\textsc{Delphes}}
\newcommand{\pyhf}{\texttt{pyhf}}
\newcommand{\musig}{\ensuremath{\mu_{\mathrm{sig}}}}
\newcommand{\hepdata}{\texttt{HEPData}}
\newcommand{\hepmc}{\textsc{hepmc}}
\newcommand{\ROOT}{\textsc{root}}
\newcommand{\json}{\texttt{json}}
\newcommand{\pt}{\ensuremath{p_{\mathrm{T}}}}
\newcommand{\easyscanhep}{\textsc{EasyScan\_HEP}}
\newcommand{\spheno}{\textsc{Spheno}}
\newcommand{\feynhiggs}{\textsc{FeynHiggs}}
\newcommand{\micromegas}{\textsc{MicrOMEGAS}}
\newcommand{\superiso}{\textsc{SuperIso}}
\newcommand{\gmtwocalc}{\textsc{GM2Calc}}
\newcommand{\recast}{\textsc{recast}}
\newcommand{\toml}{\textsc{toml}}
\newcommand{\docker}{\texttt{Docker}}
\newcommand{\singularity}{\texttt{Singularity}}
\newcommand{\apptainer}{\texttt{Apptainer}}

\newcommand{\thistitle}{Reduce, Reuse, Reinterpret: an end-to-end pipeline for recycling particle physics results}
\newbox{\myorcidaffilbox}
\sbox{\myorcidaffilbox}{\large\includegraphics[height=1.7ex]{orcid}}
\newcommand{\orcidaffil}[1]{\href{https://orcid.org/#1}{\usebox{\myorcidaffilbox}}}

\title{Reduce, Reuse, Reinterpret: an end-to-end pipeline for recycling particle physics results}

\author[ \,,1]{\orcidaffil{0000-0001-6616-3433}Giordon~Stark\thanks{\texttt{gistark@ucsc.edu}}}
\author[1,2]{Camila Aristimuno Ots}
\author[ \,,1]{\orcidaffil{0000-0001-8392-0934}Mike~Hance\thanks{\texttt{mhance@ucsc.edu}}}
\affil[1]{University of California, Santa Cruz\\ Santa Cruz Institute for Particle Physics\\1156 High Street\\Santa Cruz, CA 95064}
\affil[2]{University of Southern California\\ Liquid Propulsion Laboratory\\ 854 Downey Way, Los Angeles, CA 90089}

\renewcommand{\shorttitle}{\thistitle}

\hypersetup{
  pdftitle={\shorttitle},
  pdfsubject={q-bio.NC, q-bio.QM},
  pdfauthor={Giordon~Stark, Camila~Aristimuno~Ots, Mike~Hance},
  pdfkeywords={HEP, Reinterpretation, SUSY},
}

\begin{document}
\maketitle

\begin{abstract}
	Searches for new physics at the Large Hadron Collider have constrained many models of physics beyond the Standard Model.  Many searches also provide resources that allow them to be reinterpreted in the context of other models.  We describe a reinterpretation pipeline that examines previously untested models of new physics using supplementary information from ATLAS Supersymmetry (SUSY) searches in a way that provides accurate constraints even for models that differ meaningfully from the benchmark models of the original analysis.  The public analysis information, such as public analysis routines and serialized probability models, is combined with common event generation and simulation toolkits \madgraph, \pythia, and \delphes{} into workflows steered by \toml{} configuration files, and bundled into the \mapyde{} Python package.  The use of \mapyde{} is demonstrated by constraining previously untested SUSY models with compressed sleptons and electroweakinos using ATLAS results.
\end{abstract}


\section{Introduction}
\label{sec:introduction}

Direct searches for new phenomena at the Large Hadron Collider (LHC) have constrained many models of beyond-the-Standard-Model (BSM) physics.  A typical LHC search focuses on an experimental signature chosen for its ability to discriminate between SM and BSM sources, and benchmark the results of the search using one or more specific models.  In some cases the chosen benchmarks are representative models that solve a particular problem, while in other cases the benchmark models are simplified models~\cite{LHCNewPhysicsWorkingGroup:2011mji} that represent a broader (but still limited) parameter space within a theoretical framework such as supersymmetry (SUSY).  In either case, the experimental results as published by LHC collaborations are only strictly applicable to the benchmark models, leaving the vast majority of BSM parameter space unexplored.  Leveraging the full power of LHC data in the search for new physics requires tools that facilitate the re-use of those experimental results to test models that were not considered in the original search.  The challenge to experiments is to publish or provide enough information to enable such efforts, and the challenge to the rest of the community is to use that information to extend our understanding of what BSM theories are still viable.  These challenges form the reinterpretation problem.

Existing toolkits solve the reinterpretation problem in various ways, as described in Section III of Ref.~\cite{LHCReinterpretationForum:2020xtr} and in Refs.~\cite{Cranmer:2021urp,Bailey:2022tdz}.  Some toolkits implement existing analysis workflows in independent software frameworks which are more simulation-based: \textsc{checkmate}~\cite{Dercks:2016npn}, \textsc{MadAnalysis5}~\cite{Conte:2018vmg,Araz:2020lnp,Dumont:2014tja}, \textsc{GAMBIT}'s \textsc{ColliderBit}~\cite{GAMBIT:2017yxo,Kvellestad:2019vxm,GAMBIT:2018gjo,zenodo:gambit}, \textsc{rivet}~\cite{Bierlich:2019rhm,Bierlich:2020wms}, and Contur~\cite{Buckley:2021neu} (which interprets \textsc{rivet} outputs).  Others match simplified versions of full models to experimental results using efficiency maps, relying more on experimental data: \texttt{SModelS}~\cite{Alguero:2021dig} and \recast-based approaches~\cite{Cranmer:2010hk} such as in Refs.~\cite{zenodo:LHCreinterpretation,llpRepo,RECAST1,RECAST2,RECAST3}.  The CMS collaboration provides Simplified Likelihood~\cite{CMS-NOTE-2017-001} correlation/covariance matrices for some analyses, while the ATLAS collaboration has started to provide full probability models~\cite{ATL-PHYS-PUB-2019-029} in which additional data is encoded, such as correlations and background estimates. The \recast{} framework~\cite{Cranmer:2010hk} facilitates full production and processing of simulated events using the same software tools used by ATLAS in the physics results of interest.  This has the advantage of high accuracy and precision, but requires significant computational resources to produce fully simulated and reconstructed samples.

Recent progress in releasing full public probability models has further expanded the possibilities for reinterpreting LHC analyses.  It is no longer a technical challenge to assess the sensitivity of an LHC analysis with a public serialized probability model, including all uncertainties and correlations, to an arbitrary model of new physics.  The only challenge that remains is to evaluate the acceptance and efficiency of the analysis to the new model.  This can often be done using public event generation and detector simulation tools, informed by the experimental details of the reference analysis.

In this paper we present a new pipeline for calculating the constraints on new physics from existing analyses with public probability models. This pipeline is built using \mapyde~\cite{mapyde}, a pure-Python package that chains public tools in HEP with a single configuration file. Additionally, \mapyde{} provides a user-friendly interface to configure, run, and extend the toolchain with other tools as needed.  The \mapyde{} toolkit is described in \Cref{sec:the-toolkit}, including the software employed, the configuration, and deployment in containerized environments.  Two example uses of the \mapyde{} toolkit are provided in \Cref{sec:reinterpreting-compressed-susy-searches-from-atlas}, in which we reproduce existing ATLAS results, test a new simplified model of slepton-wino-bino production, and run a pMSSM-like scan of electroweak SUSY model parameters to test SUSY models with mixed wino-bino-higgsino states.

\section{The \mapyde{} toolkit}
\label{sec:the-toolkit}

\begin{figure}[tbp]
	\centering
	\includegraphics[width=\columnwidth]{figures/tikz/output/overview}
	\caption{Overview of the \mapyde{} toolchain and the role of each component.}
	\label{fig:mapydeoverview}
\end{figure}

This paper describes the implementation of, and results obtained with, version \texttt{v0.5.0} of \mapyde.  The \mapyde{} package provides support for using the following tools:

\begin{itemize}
	\item \madgraphfull (\madgraph)~\cite{Alwall:2014hca,Frederix:2018nkq} (event generation)
	\item \pythia~\cite{Bierlich:2022pfr} (parton shower, hadronization, decays)
	\item \delphes~\cite{deFavereau:2013fsa,Selvaggi:2014mya,Mertens:2015kba} (detector simulation)
	\item \simpleanalysis~\cite{simpleanalysis,atlas_simpleanalysis} (analysis description)
	\item \pyhf~\cite{pyhf,pyhf_joss} (probability model fitting)
\end{itemize}

and was named after the first three tools in a typical \mapyde{} simulation pipeline: \madgraph, \pythia, and \delphes{} (\textsc{MaPyDe}).  Additional tools, such as those listed in \Cref{sec:introduction}, can be supported in the analysis pipeline of this flexible framework with a little extra custom configuration, and they can be more natively supported in future versions of \mapyde{} upon request or by pull requests from external contributors.  A flow chart illustrating the role of different tools in the \mapyde{} pipeline is shown in~\Cref{fig:mapydeoverview}.

A \mapyde{} pipeline is constructed as a series of containerized transforms, with the \mapyde{} package providing configuration and steering of the individual stages.  The use of containers allows the \mapyde{} package to remain lightweight and easy to install, while still enabling event generation/simulation and subsequent data analysis steps to run on any system that provides \docker{} or \singularity/\apptainer.  Default containers are provided for \madgraph+\pythia, for \delphes, and for probability model fitting with \pyhf.  The ATLAS collaboration provides containers that implement the \simpleanalysis{} routines for many SUSY searches, including those reinterpreted in \Cref{sec:reinterpreting-compressed-susy-searches-from-atlas}.  Containers for a variety of different \madgraph+\pythia{} releases are provided in the \mapyde{} \texttt{GitHub} container registry~\cite{MapydeRegistry}.  Users can also provide their own containers for any stage of the analysis.

The \mapyde{} workflow is controlled by a user-generated dictionary that encodes the configuration for all stages of the analysis.  Templates for this dictionary are provided, and custom templates can be used to provide a consistent reference for subsequent analysis runs that modify a small number of configuration parameters.  The configuration dictionary offers direct access to selected parameters in the \madgraph{} run card, in addition to allowing the user to point towards custom process and model parameter cards.  Analyses performed with \mapyde{} can use either a command-line interface or take advantage of direct access to Python functions.  The command-line interface is implemented with the \texttt{click} Python package~\cite{click}, and it takes a \toml{}~\cite{toml} configuration file as input, which is translated internally into the configuration dictionary.  \mapyde{} also provides a \textsl{Text User Interface} (TUI) using \texttt{Textual}~\cite{textual} to support users less familiar with the command-line interface.  The Python interface to \mapyde{} can either parse a \toml{} input file or accept the configuration dictionary directly.  An example \toml{} configuration file is provided in \Cref{sec:input-configuration-for-a-slepton-sample}.

In the containers provided by \mapyde, \madgraph{} and \pythia{} are bundled together and are both launched through a \madgraph{} control file that is generated based on the \mapyde{} configuration dictionary.  The \madgraph{} outputs are stored as Les Houches Event (LHE) records~\cite{Alwall:2006yp}, and are passed directly into \pythia{} for parton showering and hadronization.  The \pythia{} outputs in \hepmc{} format are then passed into \delphes{}, or directly into \simpleanalysis{} when evaluating the acceptance of an analysis selection without detector simulation.  Outputs from \delphes{} in \ROOT{} format are passed to an intermediate stage that either analyzes the \delphes{} output or transforms it into a format able to be processed by the next step in the pipeline.  In the results presented below, we use a script that converts the \delphes{} output into a \ROOT{} file that can serve as input to the \simpleanalysis{} phase, called \texttt{Delphes2SA.py}.  The output of \simpleanalysis{} is then processed into \json{} format in another custom script called \texttt{SA2JSON.py}.  That script encodes a mapping from the branch names in the \simpleanalysis{} output file to the signal region names in the public probability model provided with the published analysis.  The result of that transform can then be used to patch the serialized probability model and perform hypothesis tests with the generated signal.  In the cases presented below, we perform the hypothesis test with the \texttt{muscan.py} script, whose output is a \json{} file containing both the 95\% confidence level upper limits on the cross section (expressed as a ratio of the cross section to the model prediction, called the signal strength and denoted \musig), as well as the full configuration dictionary used for the job.  These outputs can then be used to determine if a given set of parameters used to generate events for the hypothesis test are compatible with existing limits or not.  All outputs from intermediate stages of the analysis chain are kept to facilitate re-running the pipeline from an arbitrary starting point.

\section{Reinterpreting Compressed SUSY Searches from ATLAS}
\label{sec:reinterpreting-compressed-susy-searches-from-atlas}

We demonstrate the utility of the \mapyde{} analysis chain by reproducing and reinterpreting the results of ATLAS searches for supersymmetry.  The searches described in Ref.~\cite{ATLAS:2019lng} are optimized for SUSY models with \enquote{compressed} mass spectra, where the next-to-lightest SUSY partner (NLSP) and lightest SUSY partner (LSP) are separated by $\mathcal{O}(1-10)$ GeV in mass.  The small mass splittings imply low-momentum (soft) Standard Model decay products, since most of the momentum of the NLSP is given to the LSP.  The ATLAS searches considered here focus on final states including two low-momentum (\enquote{soft}) charged leptons, substantial missing transverse momentum (\met) from the invisible LSP's (which in this case are the lightest neutralinos, \chioz), and one or more energetic jets that boost the SUSY system.  We focus specifically on two searches from that paper: a search optimized for light sleptons (SUSY partners of the SM leptons), and a search optimized for light electroweakinos (SUSY partners of the SM electroweak bosons).

\subsection{Implementation}
\label{ssec:implementation}

We use \mapyde{} to generate, shower, and simulate SUSY events, to analyze them using \simpleanalysis, and to interpret the results using \pyhf.  The implementation corresponds to \mapyde{} version 0.5.0, with configuration cards and scripts provided in a public \texttt{GitHub} repository~\cite{mapyde-user}.  The configuration uses \madgraph{} version 2.9.3, \pythia{} version 8.306, \delphes{} version 3.5.0, and \simpleanalysis{} version 1.1.0.  The \simpleanalysis{} code runs on dedicated containers provided by ATLAS~\cite{SAGitLabRegistry}, where we use the \enquote{\texttt{EwkCompressed2018}} selection corresponding to the analyses from Ref.~\cite{ATLAS:2019lng}.  We use \pyhf{} version 0.7.2 to patch the public probability models provided in the \hepdata~\cite{HepData} repository~\cite{hepdata.91374} for Ref.~\cite{ATLAS:2019lng} with the signal yields from \mapyde, and to compute upper limits on \musig.  When reproducing the results for the same benchmark models from Ref.~\cite{ATLAS:2019lng} the \pyhf{} output is compared with limit contours provided in \hepdata.

The signal samples produced in our \mapyde{} workflow differ from those used in Ref.~\cite{ATLAS:2019lng} in three significant ways.  First, events in the ATLAS samples contained up to two jets in the matrix element in addition to a pair of SUSY particles, with different jet multiplicity processes merged in the parton shower using the CKKW-L algorithm~\cite{Lonnblad:2011xx}.  In our samples, we produce only one-jet events in \madgraph, and allow \pythia{} to model the contributions from additional emissions.  Second, the ATLAS samples use \madspin{}~\cite{Artoisenet:2012st} to perform the three-body decays of the electroweakinos to SM leptons and a \chioz, while we perform decays using \pythia.  The \mapyde{} pipeline does support the use of \madspin, but it is not used here.  Third, and most importantly, the ATLAS samples use ATLAS simulation and reconstruction software to transform the \pythia{} output into ROOT files containing physics objects, while we use \delphes.

The impact of the first two differences is evaluated by comparing the acceptance of the event selection applied to events at particle level.  ATLAS provides the acceptance of the event selection by processing particle-level events with \simpleanalysis{} as part of the public event record of the search.  We perform a similar calculation by passing the \hepmc{} event record from \pythia{} directly into \simpleanalysis{} using \mapyde.  The resulting signal region yields are then compared to the product of the ATLAS acceptance, cross section, branching ratio, and integrated luminosity.  On average we find that the \mapyde{} and ATLAS acceptances are very similar, except for very compressed points where on average the ATLAS acceptance is approximately 10\% higher.

The final difference between the ATLAS simulation framework and \mapyde{} is evaluated using signal yields and model constraints after detector simulation and tuned by modifying the efficiencies in the \delphes{} configuration card.  We focus in particular on the treatment of electrons and muons in \delphes, since these also required special handling in the ATLAS analysis.  Further details of the lepton efficiency tuning in \delphes{} are described below.

\subsection{Compressed Sleptons}
\label{ssec:compressed-sleptons}

We first reproduce the results of the ATLAS search for compressed sleptons.  The ATLAS search is optimized using a slepton-bino model, in which the slepton NLSP decays to a bino-like LSP and a charged SM lepton.  We generate events with pairs of charged sleptons (including scalar superpartners of both left- and right-handed SM leptons) and compare the leading-order (LO) cross sections calculated by \madgraph{} in an inclusive sample (without additional emissions) with the next-to-leading-order (NLO) cross sections reported by ATLAS, which do not include electroweak corrections.  We find a mass-independent NLO:LO $k$-factor of 1.18, which is used to scale the one-jet \madgraph{} samples produced with \mapyde.

After the acceptance corrections described above, the lepton efficiencies in \delphes{} are tuned to reproduce the ATLAS signal yields as documented in~\Cref{lst:delphes-electron-efficiencies,lst:delphes-muon-efficiencies}.  The efficiencies of electrons and muons after object selection are provided as part of the public record for Ref.~\cite{ATLAS:2019lng} and are the starting point for the modified \delphes{} configuration used to reproduce the ATLAS results.  We find that setting all electron and muon efficiencies in \delphes{} to the upper range of values reported in Fig. 3 of~\cite{ATLAS:2019lng} is sufficient to reproduce the results of the ATLAS slepton and electroweakino searches to adequate precision, as shown in~\Cref{fig:SleptonBino,fig:Higgsino}.  The only exception is the lowest-\pt{} bin for both electrons and muons, where the \mapyde{} efficiencies needed to reproduce the ATLAS limits are roughly 15\% higher than the values reported by ATLAS. \Cref{fig:SleptonBino} also shows the model constraints for the slepton-bino search when using the default \delphes{} configuration card, which does a reasonable job of describing the high-splitting regions, but fails to describe the most compressed mass points, which are most sensitive to the low-\pt{} lepton efficiencies provided by ATLAS.

\begin{figure}[thbp]
	\centering
	\includegraphics[width=0.75\textwidth]{{./figures/SleptonBino}}
	\caption{Constraints on the slepton-bino model from: the ATLAS paper~\cite{ATLAS:2019lng} (blue dots); \mapyde{} before tuning the \delphes{} lepton efficiencies (orange solid line); and \mapyde{} after tuning (blue solid line).}
	\label{fig:SleptonBino}
\end{figure}

With the framework tuned to the ATLAS response for compressed SUSY events, we now use \mapyde{} to assess the sensitivity of the ATLAS search to a new model.  We consider a \enquote{slepton-wino-bino} simplified model, where a light slepton decays to a wino and a SM charged lepton, as illustrated in~\Cref{fig:feynman:slepton_wino_bino}.
We set the slepton branching ratio $\tilde{\ell}\to\ell\chitz$ to 100\%, with the \chitz{} decaying to a \chioz{} and to two fermions through an off-shell $Z$ boson.  In such events, the \pt{} values of the SM leptons will be largely determined by the \slepton--\chitz{} mass gap, in contrast to the slepton-bino model where the lepton \pt{} is driven by the \slepton--\chioz{} mass gap.  In the limit of vanishing \chitz--\chioz{} mass differences, the slepton-wino-bino model described here is phenomenologically identical to the slepton-bino model.

\begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth]{{./figures/feynman/output/slepton_wino_bino}}
	\caption{Feynman diagram of slepton pair production, with slepton ($\tilde{\ell}$) decays to wino-like NLSP's ($\tilde{\chi}_2^0$), which then decay to bino-like LSP's ($\tilde{\chi}_1^0$).}
	\label{fig:feynman:slepton_wino_bino}
\end{figure}

\begin{figure}
	\centering
	\subfloat[$\Delta m(\chitz,\chioz) = 50$ GeV, $\Delta m(\slepton,\chitz) = 5$ GeV]{\includegraphics[width=0.25\textwidth]{{./figures/tikz/output/slhaplot_SleptonWinoBino_largeSleptonN1_largeN2N1}}}\hspace{1cm}
	\subfloat[$\Delta m(\chitz,\chioz) = 20$ GeV, $\Delta m(\slepton,\chitz) = 30$ GeV]{\includegraphics[width=0.25\textwidth]{{./figures/tikz/output/slhaplot_SleptonWinoBino_largeSleptonN1_mediumN2N1}}}\hspace{1cm}
	\subfloat[$\Delta m(\chitz,\chioz) = 5$ GeV, $\Delta m(\slepton,\chitz) = 50$ GeV]{\includegraphics[width=0.25\textwidth]{{./figures/tikz/output/slhaplot_SleptonWinoBino_largeSleptonN1_smallN2N1}}}
	\caption{Mass hierarchies for large $\Delta m(\slepton, \chioz)$ splittings for different splittings of $\Delta m(\chitz,\chioz)$ being (a) large, (b) intermediate, and (c) small. In all figures, $m(\slepton) = 130$ GeV.}
	\label{fig:slhaplots}
\end{figure}

We parameterize the model in terms of the slepton mass, the \slepton-\chioz{} mass gap, and the \chitz-\chioz{} mass gap, to allow us to display the model constraints in the same plane as the slepton-bino results from ATLAS.  The resulting constraints (both expected and observed) are shown in~\Cref{fig:SleptonWinoBino,fig:SleptonWinoBinoLog} for a range of \chitz-\chioz{} splittings.  At small $\Delta m(\chitz,\chioz)$ the results resemble those of the ATLAS slepton-bino model, since the \chitz{} is nearly degenerate with the \chioz{} leading to virtually no kinematic difference arising from the additional soft decay products.  By contrast, for large \chitz-\chioz{} splittings (dark blue contour lines), the requirement that the slepton must decay through a \chitz{} results in stronger constraints at large \slepton-\chioz{} differences.  For each model considered, the contour is prevented from covering arbitrarily small values of $\Delta m(\slepton,\chitz)$ by the fact that such models produce softer SM leptons and lower lepton efficiences. Similarly, the contour is bounded from above by the reduced cross-section due to larger slepton masses, and by ATLAS analysis selections, which were optimized for compressed decays, and which are sensitive to the momenta of the fermions from the $\chitz$ decay. For models with large $\Delta m(\slepton, \chioz)$, the second-lightest neutralino \chitz{} has more allowed phase-space illustrated in~\Cref{fig:slhaplots}.

\begin{figure}
	\centering
	\subfloat[expected]{\includegraphics[width=0.75\textwidth]{{./figures/SleptonWinoBino_exp}}}\\
	\subfloat[observed]{\includegraphics[width=0.75\textwidth]{{./figures/SleptonWinoBino_obs}}}
	\caption{Expected (a) and observed (b) constraints on the slepton-wino-bino model.  The model is parameterized by the slepton mass, the slepton-\chioz{} mass splitting, and the \chitz-\chioz{} splitting, and compared against the slepton-bino results from Ref.~\cite{ATLAS:2019lng}.}
	\label{fig:SleptonWinoBino}
\end{figure}

\begin{figure}
	\centering
	\subfloat[expected]{\includegraphics[width=0.75\textwidth]{{./figures/SleptonWinoBino_exp_log}}}\\
	\subfloat[observed]{\includegraphics[width=0.75\textwidth]{{./figures/SleptonWinoBino_obs_log}}}
	\caption{Expected (a) and observed (b) constraints on the slepton-wino-bino model, shown in logarithmic scale.  The model is parameterized by the slepton mass, the slepton-\chioz{} mass splitting, and the \chitz-\chioz{} splitting, and compared against the slepton-bino results from Ref.~\cite{ATLAS:2019lng}.}
	\label{fig:SleptonWinoBinoLog}
\end{figure}

This class of models, while being less \enquote{simplified} than the slepton-bino model traditionally studied by LHC experiments, includes models that nominally escape constraint by both existing slepton-bino searches as well as direct searches for electroweakinos.  In particular, the wino-bino constraints reported in Ref.~\cite{ATLAS:2019lng} constrain electroweakinos with \chitz-\chioz{} splittings as low as 1 GeV only for electroweakino masses near 100 GeV.  In the slepton-wino-bino results shown in Fig.~\ref{fig:SleptonWinoBino} we find that the ATLAS search excludes models with 1 GeV \chitz-\chioz{} splittings up to slepton masses of well over 200 GeV, which implies limits on \chioz{} masses also exceed 200 GeV for small slepton-\chioz{} splittings.

\subsection{Compressed Electroweakinos}
\label{ssec:compressed-electroweakinos}

The ATLAS search for compressed electroweakinos considered two different simplified models: one with \enquote{pure} Higgsino-like \chitz, \chiopm, and \chioz{} states, and another with wino-like \chitz/\chiopm{} and bino-like \chioz.  We focus on the Higgsino model to validate the \mapyde{} output.  Following a procedure similar to the validation of the ATLAS slepton-bino results described above, we generate a grid of Higgsino model points to reproduce the ATLAS results.  The \mapyde{} electroweakino samples use the same $k$-factor and lepton efficiencies as the slepton search.  The comparison between the \mapyde{} and ATLAS results is shown in~\Cref{fig:Higgsino}, where the \mapyde{} exclusion contour provides somewhat more coverage than the corresponding ATLAS contour, in contrast to the slepton-bino validation where the \mapyde{} results were slightly weaker than ATLAS over most of the model space.

\begin{figure}
	\centering
	\includegraphics[width=0.75\textwidth]{{./figures/Higgsino}}
	\caption{Constraints on the \enquote{pure Higgsino} simplified model from ATLAS (blue dots) and \mapyde{} (purple solid line).}
	\label{fig:Higgsino}
\end{figure}

\begin{figure}
	\centering
	\subfloat[one-step]{\includegraphics[width=0.4\textwidth]{{./figures/feynman/output/ewkino_onestep}}}\hspace{2cm}
	\subfloat[two-step]{\includegraphics[width=0.4\textwidth]{{./figures/feynman/output/ewkino_twostep}}}
	\caption{Example feynman diagrams of possible electroweakino decays with (a) $\chitpm\to\chioz$ and (b) $\chitpm\to\chitz$.  The $W$-boson comes from $\chitpm$ in both cases.}
	\label{fig:feynman:ewkinos}
\end{figure}

We next use \mapyde{} to assess the ATLAS sensitivity to MSSM SUSY models in which the bino, wino, and Higgsino mass terms ($M_1$, $M_2$, and $\mu$, respectively) are all relatively low, leading to \enquote{wino-bino-Higgsino} models that have potentially rich phenomenologies. Some example models are illustrated in~\Cref{fig:feynman:ewkinos}.  In these models, the $W$-boson is treated as off-shell for the \enquote{compressed} phase-space under study in this paper.  We use a pMSSM scanning tool (\easyscanhep~\cite{Shang:2023gfy,Han:2016gvr}) to generate particle spectra for models with $M_1$, $M_2$, and $\mu$ ranging from $-500$ GeV to 500 GeV, sampled with flat priors.
Particle masses are calculated using \spheno~\cite{Porod:2003um,Porod:2011nf} and stored in the SUSY Les Houches Accord (SLHA) format~\cite{Allanach:2008qq}.  Additional tools are run as described in~\Cref{sec:easyscan-hep-configuration} and are used to calculate values for the selection criteria shown in~\Cref{lst:mask}.  Since our goal is to investigate models with compressed electroweakino mass spectra accessible to ATLAS Run-2 searches, we select models that satisfy $m(\chioz) > 100$ GeV, $m(\chithz)<300$ GeV, and $(m(\chithz)-m(\chioz))<50$ GeV for further study.  We further require that any selected models have valid output from the spectrum generator \spheno~\cite{Porod:2003um,Porod:2011nf}, have a valid Higgs mass as computed by \feynhiggs~\cite{Bahl:2018qog,Bahl:2017aev,Bahl:2016brp,Hahn:2013ria,Frank:2006yh,Degrassi:2002fi,Heinemeyer:1998np,Heinemeyer:1998yj}, and to satisfy dark matter constraints implemented in \micromegas~\cite{Belanger:2020gnr}, flavor physics constraints implemented in \superiso~\cite{Arbey:2018msw}, and muon $g-2$ constraints implemented in \gmtwocalc~\cite{Athron:2015rva,Athron:2021evk}.  The SLHA records for the selected 81 models are used as inputs for event generation with \mapyde.  Branching ratios for electroweakino decays are taken directly from the \spheno{} output.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{python}
    (SP_m_h!=-1) & (SPfh_m_h!=-1) & (MO_Omega!=-1) # spheno, feynhiggs, micromegas: ok
    & (SI_BR_Bs_to_mumu!=-1) & (GM2_gmuon!=-1) # superiso, gm2calc: ok
    & (SP_m_chi_10>100) & (abs(SP_m_chi_30)<300) # N1 > 100 GeV, N3 < 300 GeV
    & ((abs(SP_m_chi_30)-abs(SP_m_chi_10))<50) # m(N3, N1) < 50 GeV
  \end{minted}
	\caption{The mask used to define the selection of models for assessing the ATLAS sensitivity to Higgsino-Win
		We next use \mapyde{} to assess the ATLAS sensitivity to MSSM SUSY models in which the bino, wino, and Higgsino o models.}
	\label{lst:mask}
\end{listing}

The ATLAS constraints on the wino-bino-higgsino model scan are parameterized in terms of the mass of the \chitz{} and the mass difference $\Delta m=m(\chitz)-m(\chioz)$, to facilitate comparisons with the pure-Higgsino constraints from ATLAS.  The models under study are binned in a coarse grid in the $\Delta m$ vs $m(\chitz)$ plane, and the fraction of excluded models is calculated for each bin.  The expected and observed constraints on these models are shown in~\Cref{fig:EWKino_pmssm}, with the ATLAS Higgsino results overlaid for comparison.  In general the selected pMSSM points are more constrained than those of a pure-Higgsino model at larger mass splittings, likely due to the presence of the additional \chithz{} and its own decays to final states similar to that of the \chitz.

\begin{figure}
	\centering
	\subfloat[expected]{\includegraphics[width=0.75\textwidth]{{./figures/EWKino_pmssm_exp}}}\\
	\subfloat[observed]{\includegraphics[width=0.75\textwidth]{{./figures/EWKino_pmssm_obs}}}
	\caption{Expected (a) and observed (b) constraints on wino-bino-higgsino models containing at least three light neutralinos.  Black dots represent the specific model points used to calculate the fraction of excluded models within a bin, shown in color.  White bins contain no models from the current scan.  Results from an ATLAS search~\cite{ATLAS:2019lng} for pure Higgsinos are overlaid in blue dots.}
	\label{fig:EWKino_pmssm}
\end{figure}

\section{Conclusion}
\label{sec:conclusion}

The combination of rich physics results from the LHC with public supplementary material, including analysis routines and probability models, has opened the door to new ways of quantifying constraints on unexplored models of BSM physics with already-published results.  We demonstrated one such pipeline, implemented in the \mapyde{} Python package, that facilitates the re-use of LHC analyses.  We illustrated the utility of a user-friendly Python package, \mapyde{}, by probing previously-untested models of supersymmetry, including a simplified model of sleptons that undergo cascade decays to wino-like and bino-like electroweakinos, and a parameter scan of highly-mixed higgsino, wino, and bino states with a rich set of possible decay chains.  In both cases we find that existing searches are able to constrain non-trivial regions of parameter space that would have been difficult or impossible to predict by simple extrapolations of existing results.

\section{Acknowledgments}
\label{sec:acknowledgments}

We thank Sam English, Bryn Lonsbrough, Len Morales Zaragoza, Zach Dethloff, and Ryota Johnson for suffering with early versions of scripts that would later develop into \mapyde.  We thank Zach Marshall, Jeff Shahinian, and Jason Nielsen for reading early drafts of this work and providing useful comments.  Hance and Stark are supported by the Department of Energy Office of Science grant DE-SC0010107.

\printbibliography

\appendix

\newpage

\section{Lepton Efficiencies in \delphes} \label{sec:lepton-efficiencies-in-delphes}
\begin{listing}[H]
	\inputminted[frame=single,framesep=2mm,firstline=476,lastline=491]{ini}{{auxdata/delphes_card_ATLAS_lowptleptons_sleptons_notrackineffic.tcl}}
	\caption{A snippet from the \mapyde-provided \delphes{} configuration for electron efficiencies. The portion that is commented out is what comes from the default ATLAS configuration. These numbers come from Ref.~\cite{ATLAS:2019lng}.}
	\label{lst:delphes-electron-efficiencies}
\end{listing}

\begin{listing}[H]
	\inputminted[frame=single,framesep=2mm,firstline=514,lastline=531]{ini}{{auxdata/delphes_card_ATLAS_lowptleptons_sleptons_notrackineffic.tcl}}
	\caption{A snippet from the \mapyde-provided \delphes{} configuration for muon efficiencies. The portion that is commented out is what comes from the default ATLAS configuration. These numbers come from Ref.~\cite{ATLAS:2019lng}.}
	\label{lst:delphes-muon-efficiencies}
\end{listing}

\newpage
\section{EasyScan\_HEP Configuration}
\label{sec:easyscan-hep-configuration}

We used an \easyscanhep \texttt{ini} configuration file that defined the scan ranges in~\Cref{lst:easyscanini} as well as additional programs to run, described in the text above. The specific versions used are:

\begin{itemize}
	\item \easyscanhep{} (\texttt{v1.0.0}): pMSSM scanning and program control~\cite{Shang:2023gfy,Han:2016gvr}
	\item \spheno{} (\texttt{v4.0.4}): spectrum generator~\cite{Porod:2003um,Porod:2011nf}
	\item \feynhiggs{} (\texttt{v2.16.0}): Higgs mass calculation~\cite{Bahl:2018qog,Bahl:2017aev,Bahl:2016brp,Hahn:2013ria,Frank:2006yh,Degrassi:2002fi,Heinemeyer:1998np,Heinemeyer:1998yj}
	\item \micromegas{} (\texttt{v5.2.1}): Dark Matter calculations (e.g., relic density)~\cite{Belanger:2020gnr}
	\item \superiso{} (\texttt{v4.0}): Flavor Physics observables~\cite{Arbey:2018msw}
	\item \gmtwocalc{} (\texttt{v2.0.0}): $g-2$ calculation~\cite{Athron:2015rva,Athron:2021evk}
\end{itemize}

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[scan]
Scan method:       random
#                  ID     Prior  Min    MAX
Input parametes:   tanb,  Flat,  1,     60
                   M_1,   Flat,  -500,  500
                   M_2,   Flat,  -500,  500
                   M_3,   Flat,  2000,  2000
                   AT,    Flat,  2000,  2000
                   Ab,    Flat,  2000,  2000
                   Atau,  Flat,  2000,  2000
                   MU,    Flat,  -500,  500
                   mA,    Flat,  2000,  2000
                   meL,   Flat,  2000,  2000
                   mtauL, Flat,  2000,  2000
                   meR,   Flat,  2000,  2000
                   mtauR, Flat,  2000,  2000
                   mqL1,  Flat,  2000,  2000
                   mqL3,  Flat,  2000,  2000
                   muR,   Flat,  2000,  2000
                   mtR,   Flat,  2000,  2000
                   mdR,   Flat,  2000,  2000
                   mbR,   Flat,  2000,  2000
  \end{minted}
	\caption{A portion of the \texttt{easyscan.ini} configuration defining the random sampling for the electroweakinos scan.}
	\label{lst:easyscanini}
\end{listing}

\section{Input \toml{} Configuration for a Slepton Sample}
\label{sec:input-configuration-for-a-slepton-sample}

The configuration dictionary used within \mapyde{} can be created as a Python dictionary and passed to \mapyde{} through the Python interface, or can be generated from a \toml{} configuration file.  We provide an example \toml{} configuration file below.  The code in this section represents a single file, but is described in blocks for easier interpretation.

\subsection{The \texttt{base} block}
\label{ssec:the-base-block}

The \texttt{base} block provides \mapyde{} with paths for inputs and outputs of the analysis pipeline.  Users can take advantage of pre-generated configuration cards \pythia{} and \delphes, but will usually at least need to define their own process cards for generating events with \madgraph.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[base]
path = "{{PWD}}"
output = "output"
logs = "logs"
data_path = "{{MAPYDE_DATA}}"
cards_path = "{{MAPYDE_CARDS}}"
scripts_path = "{{MAPYDE_SCRIPTS}}"
process_path = "{{MAPYDE_CARDS}}/process/"
param_path = "{{MAPYDE_CARDS}}/param/"
run_path = "{{MAPYDE_CARDS}}/run/"
pythia_path = "{{MAPYDE_CARDS}}/pythia/"
delphes_path = "{{MAPYDE_CARDS}}/delphes/"
madspin_path = "{{MAPYDE_CARDS}}/madspin/"
likelihoods_path = "{{MAPYDE_LIKELIHOODS}}"
        \end{minted}
	\caption{The \texttt{base} block of an example \toml{} configuration file for generating slepton events.}
	\label{slepton-config-base}
\end{listing}

Note that in~\Cref{slepton-config-base}, the \texttt{template} is left undefined, which means that the base template shipped with \mapyde{} will be loaded in. This behavior can be disabled by setting \texttt{template = false}. The (nested) template inheriting behavior for \toml{} configuration parsing enables defining grid scans more cleanly with less duplicated code.

\subsection{The \texttt{madgraph} block}
\label{ssec:the-madgraph-block}

The \texttt{madgraph} block defines some top-level options for running madgraph, such as:

\begin{itemize}
	\item whether or not to skip the \madgraph{} job, sometimes useful when re-running an analysis chain and re-using LHE inputs from a previous job
	\item the name of the \texttt{param} card to use, in this example making use of a \toml{} feature that allows references to other \toml{} parameters
	\item the number of jobs to run in parallel when generating \madgraph{} events and when processing those events in \pythia
	\item the name of the container that provides the version of \madgraph{} to use, in this case version 2.9.3 (taken from the \texttt{GitHub} container registry)
\end{itemize}



These options, and options from subsequent \madgraph-related blocks, are processed by \mapyde{} to produce a \madgraph{} run script.  The \texttt{madgraph.generator} block only specifies the name of that run script.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[madgraph]
skip = false
params = "SleptonBino"
paramcard = "{{madgraph['params']}}.slha"
cores = 1
batch = false
version = "madgraph:2.9.3"

[madgraph.generator]
output = "run.mg5"
        \end{minted}
	\caption{The \texttt{madgraph} block of an example \toml{} configuration file for generating slepton events.}
	\label{slepton-config-madgraph}
\end{listing}


\subsection{The \texttt{madgraph.masses} block}
\label{ssec:the-madgraph-masses-block}

The \texttt{madgraph.masses} block enables the use of user-defined substitutions in the SLHA param card.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[madgraph.masses]
MSLEP = 250
MN1 = 240
        \end{minted}
	\caption{The \texttt{madgraph.masses} block of an example \toml{} configuration file for generating slepton events.}
	\label{slepton-config-masses}
\end{listing}

In the example above, the slepton masses in the SLHA file have been replaced with the string \texttt{'{{MSLEP}}'}, which \mapyde{} then substitutes with the value of 250 GeV at run-time.  This allows a single param-card template to be used for jobs that want to keep most parameters fixed, but vary one or more parameters as part of a parameter scan.

\subsection{The \texttt{madgraph.run} blocks}
\label{ssec:the-madgraph-run-blocks}

The \texttt{madgraph.run} blocks exposes the \madgraph{} run card to the \mapyde{} configuration dictionary.  The \texttt{madgraph.run} block defines the name of the \madgraph{} run card, which will be accessed via the \texttt{run\_path} defined in the \texttt{base} block as well as some commonly-changed run parameters: \texttt{nevents}, \texttt{iseed}, and \texttt{ecms}.  The \texttt{madgraph.run.options} block defines modifications to be made to the \madgraph{} run card.  In the example below, default values for \texttt{mmjj}, \texttt{ptj}, and \texttt{ptj1min} are overwritten by the values provided in the \toml{} configuration file.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[madgraph.run]
card = "default_LO.dat"
ecms = 13000
nevents = 50000
seed = 0

[madgraph.run.options]
mmjj = 500
ptj = 20
ptj1min = 50
        \end{minted}
	\caption{The \texttt{madgraph.run} blocks of an example \toml{} configuration file for generating slepton events.}
	\label{slepton-config-run}
\end{listing}


\subsection{The \texttt{madgraph.proc} block}
\label{ssec:the-madgraph-proc-block}

The \texttt{madgraph.proc} block defines the name of the process card that contains the hard process information for \madgraph. \Cref{slepton-config-proc} shows an example using an existing process card, while ~\Cref{slepton-config-proc-contents} creates a new one from the specified \texttt{contents}.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[madgraph.proc]
name = "isrslep"
card = "{{madgraph['proc']['name']}}"
contents = false
  \end{minted}
	\caption{The \texttt{madgraph.proc} block of an example full \toml{} configuration file for generating slepton events.}
	\label{slepton-config-proc}
\end{listing}

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[madgraph.proc]
name = "isrslep"
card = false
contents = """\
set ...
define susystrong ...
define ...
generate p p > chsleptons chsleptons j / susystrong @1
output -f
"""
  \end{minted}
	\caption{The \texttt{madgraph.proc} block demonstrating how to create a process card on-the-fly using \texttt{contents} to generate slepton events.}
	\label{slepton-config-proc-contents}
\end{listing}

\subsection{The \texttt{madspin} block}
\label{ssec:the-madspin-block}

The \texttt{madspin} block defines the name of the \madspin{} card, in jobs where \madspin{} is run.  The running of \madspin{} can be skipped if it is not needed.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[madspin]
skip = true
card = ''
        \end{minted}
	\caption{The \texttt{madgraph.run} block of an example \toml{} configuration file for generating slepton events.}
	\label{slepton-config-madpsin}
\end{listing}

\subsection{The \texttt{pythia} block}
\label{ssec:the-pythia-block}

The \texttt{pythia} block holds all configuration information for \pythia.  It defines the name of the \pythia{} configuration file, controls whether \pythia{} is run or not, and allows the passing of some additional options that will be appended to the \pythia{} configuration card.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[pythia]
skip = false
card = "pythia8_card.dat"
additional_opts = ""
        \end{minted}
	\caption{The \texttt{pythia} block of an example \toml{} configuration file for generating slepton events.}
	\label{slepton-config-pythia}
\end{listing}

\subsection{The \texttt{delphes} block}
\label{ssec:the-delphes-block}

The \texttt{delphes} block holds all configuration information for the \delphes{} stage.  It defines the name of the \texttt{tcl} configuration card, the name of the container that provides \delphes (\texttt{version}), and the name of the output file.  The input is assumed to be the \texttt{hepmc} output from a previous \pythia{} job.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[delphes]
skip = false
card = "delphes_card_ATLAS_lowptleptons_sleptons_notrackineffic.tcl"
version = "delphes"
output = "delphes/delphes.root"
        \end{minted}
	\caption{The \texttt{delphes} block of an example \toml{} configuration file for generating slepton events.}
	\label{slepton-config-delphes}
\end{listing}

\subsection{The \texttt{analysis} block}
\label{ssec:the-analysis-block}

The \texttt{analysis} block defines any transform that comes after the \delphes{} stage.  In the example code below, the script \texttt{Delphes2SA.py} will transform the \ROOT{} output from \delphes{} into a \ROOT{} file that can be processed by \simpleanalysis.  This stage also allows the implementation of scale factors (\texttt{kfactor}) that are applied to the event weights from the \delphes{} output.  Scaling of the \delphes{} outputs to a total integrated luminosity is also facilitated by the \texttt{lumi} flag.  The cross section used to calculate event weights can be over-ridden with the \texttt{XSoverride} flag, which is multiplied by the \texttt{kfactor} to define the final cross section.  Users can also provide their own scripts to run at this stage, which can choose to implement or ignore the options in this example configuration.  Running multiple scripts can be accomplished in at least two different ways: by wrapping multiple scripts and having \mapyde{} call the wrapper, or by calling \mapyde{} multiple times with separate configuration files that differ only in the script name.

The code defined with the \texttt{script} flag is run within the same container as the \delphes{} stage, to allow the use of \delphes{} libraries for analyzing the output \ROOT{} file.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[analysis]
script = "Delphes2SA.py"
XSoverride = -1
kfactor = 1.18
output = "analysis/Delphes2SA.root"
lumi = 139000
        \end{minted}
	\caption{The \texttt{analysis} block of an example \toml{} configuration file for generating slepton events.}
	\label{slepton-config-analysis}
\end{listing}

\subsection{The \texttt{simpleanalysis} block}
\label{ssec:the-simpleanalysis-block}

The \texttt{simpleanalysis} block defines the inputs, outputs, and analysis code to be run in the \simpleanalysis{} stage.  The output filenames will be given the \texttt{name} of the \simpleanalysis{} algorithm (here \texttt{EwkCompressed2018}, also see~\Cref{lst:analysiscodenaming}), with the optional \texttt{outputtag} appended.  This is particularly useful in cases where the input is specified as \texttt{hepmc}, indicating the output from \pythia{} should be analyzed, rather than the output from \delphes.  In such cases, specifying an \texttt{outputtag} like \texttt{\_hepmc} can help to distinguish between those results and the results of running \simpleanalysis{} on \delphes{} output.  Currently \mapyde{} only supports the definition of a single \simpleanalysis{} stage in the pipeline, so multiple \simpleanalysis{} transforms, e.g., one for \delphes{} inputs and one for \hepmc{} inputs, need to be performed using separate configurations.

\begin{listing}[H]
	\inputminted[firstline=1,lastline=3]{cpp}{auxdata/ANA-SUSY-2019-08.cxx}
	\caption{A snippet of \texttt{SimpleAnalysisCodes/src/ANA-SUSY-2019-08.cxx}~\cite{SAGitLab} showing how the analysis name is defined.}
	\label{lst:analysiscodenaming}
\end{listing}

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[simpleanalysis]
name = "EwkCompressed2018"
input = ""
outputtag = ""
        \end{minted}
	\caption{The \texttt{simpleanalysis} block of an example \toml{} configuration file for generating slepton events.}
	\label{slepton-config-sa}
\end{listing}

\subsection{The \texttt{sa2json} block}
\label{ssec:the-sa2json-block}

The \texttt{sa2json} block controls the translation of the \simpleanalysis{} outputs in \ROOT{} file format to a \json{} patch file that can be used to update the probability model for statistical inference.  This stage requires an understanding of the \simpleanalysis{} output format, and how to relate that output to the names of signal regions defined in the public probability model from \hepdata.  An example is provided by the \texttt{SA2JSON.py} script in \mapyde, but each serialized probability model will need a custom translation script.  The \mapyde{} developers welcome contributions of such scripts to the \mapyde{} code base.

The \texttt{image} tag controls the name of the container to be used when running the transform, while the \texttt{input} and \texttt{output} options point to the \simpleanalysis{} outputs and output \json{} filename, respectively.  The \texttt{options} entry collects command-line options for the \texttt{SA2JSON.py} script.  In this case, \texttt{-c} tells \texttt{SA2JSON.py} to perform a special selection for the compressed electroweak SUSY searches provided by the \texttt{EwkCompressed2018} \simpleanalysis{} selection.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[sa2json]
inputs = "{{simpleanalysis['name']}}{{simpleanalysis['outputtag']}}.root"
image = "pyplotting:latest"
output = "{{simpleanalysis['name']}}{{simpleanalysis['outputtag']}}_patch.json"
options = "-c"
        \end{minted}
	\caption{The \texttt{sa2json} block of an example \toml{} configuration file for generating slepton events.}
	\label{slepton-config-sa2json}
\end{listing}

\subsection{The \texttt{pyhf} block}
\label{ssec:the-pyhf-block}

The \texttt{pyhf} block controls the options for running \pyhf{} on an input probability model.  The \texttt{image} flag controls the container to use for running \pyhf.  The serialized model, provided in \json{} format, is specified with the \texttt{likelihood} flag.  The \texttt{gpu-options} and \texttt{other-options} flags both pass command-line arguments to the script \texttt{muscan.py}, provided as part of the \mapyde{} package, which performs a scan of the signal strength, \musig.  If the container includes support for a GPU (such as the CUDA libraries provided in \texttt{pyplotting:latest-cuda11} container), and a GPU is present, then \pyhf{} will use the \texttt{jax} backend and perform the calculations using the GPU.  In the example below, the \texttt{-c} option tells \texttt{muscan.py} to not use a GPU even if it is available (and to use the CPU instead), while the \texttt{-b jax} option tells \texttt{muscan.py} to use the \texttt{jax} backend for calculations.

\begin{listing}[H]
	\begin{minted}[frame=single,framesep=2mm]{ini}
[pyhf]
script = "muscan.py"
skip = false
likelihood = "Slepton_bkgonly.json"
image = "pyplotting:latest"
gpu-options = "-c -B jax"
other-options = ""
  \end{minted}
	\caption{The \texttt{pyhf} block of an example \toml{} configuration file for generating slepton events.}
	\label{slepton-config-pyhf}
\end{listing}

\end{document}
